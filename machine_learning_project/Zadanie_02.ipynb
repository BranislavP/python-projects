{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 - Branislav Pecher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(data, shift, scale):\n",
    "    return (np.array(data) - float(shift))/scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratívna analýza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprv si potrebujeme načítať dáta do premennej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dáta máme načítané tak si môžeme pozrieť či obsahujú nejaké NaN hodnoty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.shape[0] - train_data.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že žiadne NA hodnoty sa v trénovacích dátach nenachádzajú a teda máme o starosť menej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ešte si môžeme pozrieť ako sú jednotlivé dáta rozdelené."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pridám si ešte aj namerané výsledky pre trénovacie dáta aby som mohol porovnať aj tieto a následne trénovať."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data[\"class\"] = pd.read_csv(\"train_target.csv\", names = [\"class\"])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urobím si histogramy pre jednotlivé stĺpce aby som odhalil, či sa mi tu niekde nachádza outlier, poprípade aby som zistil aký tvar majú dáta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(train_data.columns)):\n",
    "    train_data.hist(column = train_data.columns.values[i], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z grafov sme zistli, že veľmi veľa parametrov je veľmi silno zaťažených na jednu hodnotu (power law), až do takej miery, že v niektorých prípadoch zvyšné hodnoty nie je možné z histogramu odčítať, a teda toto bude treba v ďalšej kapitole ošetriť. Zároveň sme zistili, že sa tu nachádza zopár outlierov a teda ich vyhodím. Pri niektorých grafoch nie je možné zistiť či sa tam nenachádzajú outlieri a teda k vyhadzovaniu outlierom sa ešte vrátim po transformácii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidím, že veľké percento dát má zadanú hodnotu triedy 0 čo je nezaradená trieda z dát. Keďže je to tak veľmi naklonené na jednu stranu tak bude zrejme treba znížiť významnosť tejto triedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z exploratívnej analýzy vidím, že žiadne NA hodnoty sa pri týchto dátach nenachádzajú. Tiež vidím, že väčšina parametrov má celkom zlé rozdelenie a je veľmi silno zaťažená na jendu hodnotu. Zároveň aj vidím, že pri predikcii si bude treba dávať pozor na váhu triedy 0, keďže má veľmi silné zastúpenie v trénovacích dátach a teda aby nám neovplyvňovala výsledky - aby sa všetko nepredikovalo ako trieda 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sme dáta reálne mohli použiť, tak ich treba najprv normalizovať. Taktiež vyhodím stĺpce, ktoré nám nedávajú žiadnu výpovednú hodnotu - tie čo majú iba jednu hodnotu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list = ['cli_pl_body', 'cli_cont_len', 'aggregated_sessions', 'net_samples', 'tcp_frag', 'tcp_ooo',\n",
    "             'cli_tcp_ooo', 'cli_tcp_frag', 'cli_win_zero', 'cli_tcp_full', 'cli_pl_change', 'srv_tcp_ooo',\n",
    "             'srv_tcp_frag', 'srv_win_zero', 'cli_tx_time', 'proxy', 'sp_healthscore', 'sp_req_duration',\n",
    "             'sp_is_lat', 'sp_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_data = pd.DataFrame()\n",
    "box_param = pd.DataFrame(data=None, columns=train_data.columns,index=range(0,1))\n",
    "for word in list(train_data.columns.values):\n",
    "    if word == 'class':\n",
    "        transformed_data['class'] = train_data['class']\n",
    "    elif word not in name_list:\n",
    "        transformed_data[word], box_param[word][0] = boxcox(train_data[word] + 1)\n",
    "\n",
    "transformed_data.head()\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentile = pd.DataFrame(data=None, columns=transformed_data.columns,index=range(0,2))\n",
    "for word in list(transformed_data.columns.values):\n",
    "    if word not in name_list and word != 'class':\n",
    "        percentile[word][0] = np.percentile(transformed_data[word], 25)\n",
    "        percentile[word][1] = np.percentile(transformed_data[word], 75)\n",
    "        transformed_data[word] = normalization(transformed_data[word], np.percentile(transformed_data[word], 25), np.percentile(transformed_data[word], 75))\n",
    "    transformed_data.hist(column = word, bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po normalizácií už sú dáta v lepšej podobe a vidím, že sa tu zopár outlyerov nachádza preto ich vyhodím. Za outlyera považuje každú hodnotu ktorá je väčšia ako trojnásobok štandardnej odchýlky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in list(transformed_data.columns.values):\n",
    "    if word != 'class':\n",
    "        mean = np.mean(transformed_data[word])\n",
    "        std = np.std(transformed_data[word])\n",
    "        transformed_data = transformed_data[transformed_data[word] < mean + 3*std]\n",
    "        transformed_data = transformed_data[transformed_data[word] > mean - 3*std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in list(transformed_data.columns.values):\n",
    "    transformed_data.hist(column = word, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z histogramov vidíme, že dáta by už mali byť očistené dáta od outlierov (dalo by sa s nimi urobiť niečo iné ale, keďže máme veľa dát tak som sa ich rozhodol odstrániť) a normalizované na normálny tvar a teda ich môžem začat používať. Keďže však výsledné triedy sú veľmi silno zatažené na jednu hodnotu (hodnota 0, čiže neklasifikované), rozhodol som sa vyhádzať 90% tých riadkov, v ktorých trieda je 0 aby som predišiel možnému zameraniu na túto triedu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in np.random.rand(len(transformed_data)):\n",
    "    array.append(i > 0.9)\n",
    "    \n",
    "undersampled_data = transformed_data[(transformed_data['class'] != 0) | (array)]\n",
    "del transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undersampled_data.hist(column='class', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z histogramu môžeme vidieť, že po odstránení 90% zástupcov triedy 0, je už rozdelenie viac vyvážené a že zastúpenie triedy 0 je približne rovnaké ako aj ostatných."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vyber klasifikatorov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozhodol som sa vyskúšať zopár klasifikátorov a porovnať ich medzi sebou aby som mohol vybrať ten najlepší. Vyskúšal som kNN klasifikátor, Naivného Gausovského Bayesa, SVM a Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprv si ale budem musiet načítať a upraviť validačné dáta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = pd.read_csv(\"valid.csv\", sep='\\t')\n",
    "trans_valid = pd.DataFrame()\n",
    "for word in list(valid_data.columns.values):\n",
    "    if word not in name_list:\n",
    "        trans_valid[word] = boxcox(valid_data[word] + 1, lmbda=box_param[word][0])\n",
    "\n",
    "del valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in list(trans_valid.columns.values):\n",
    "    if word not in name_list:\n",
    "        trans_valid[word] = normalization(trans_valid[word], percentile[word][0], percentile[word][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_test = np.genfromtxt(\"valid_target.csv\", delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ešte budem musieť rozdeliť trénovacie dáta na normálne na ktorých sa trénuje a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = undersampled_data.drop(\"class\", 1), undersampled_data[\"class\"]\n",
    "del undersampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď už mám dáta v pamäti, môžem porovnávať klasifikátori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Nasledujúce modely budú mať možnosť trénovania dvoma spôsobmi - jeden na jednorázové použitie a druhý na ukladanie natrénovaného modelu. Púšťať obidva nemá moc zmysel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('bayes.pk1'):\n",
    "    bayes = joblib.load('bayes.pk1')\n",
    "else:\n",
    "    bayes = GaussianNB().fit(X, y)\n",
    "    joblib.dump(bayes, 'bayes.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = bayes.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('bayes.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv bayes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že úspešnosť je dosť zlá a teda sám o sebe nie je Naivný Bayes moc použiteľný."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbour = KNeighborsClassifier(5).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('neighbours.pk1'):\n",
    "    neighbour = joblib.load('neighbours.pk1')\n",
    "else:\n",
    "    neighbour = KNeighborsClassifier(5).fit(X, y)\n",
    "    joblib.dump(bayes, 'neighbours.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = neighbour.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('neighbour.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv neighbour.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že úspešnosť je už lepšia avšak rýchlosť predikcie je značne pomalá a teda tento model nie je moc dobrý na predikciu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = svm.SVC().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('svm.pk1'):\n",
    "    svm = joblib.load('svm.pk1')\n",
    "else:\n",
    "    svm = svm.SVC().fit(X, y)\n",
    "    joblib.dump(svm, 'svm.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = svm.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('svm.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv svm.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že úspešnosť je celkom dobrá, avšak model je absolútne nepoužiteľný kvôli rýchlosti predikcie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=42).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('tree.pk1'):\n",
    "    tree = joblib.load('tree.pk1')\n",
    "else:\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=42).fit(X, y)\n",
    "    joblib.dump(tree, 'tree.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = tree.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('tree.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv tree.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že úspešnosť stromčeku je najlepšia z vyskúšaných modelov a taktiež aj predikcia je veľmi rýchla avšak sám o sebe nemá moc vysokú úspešnosť a teda ho bude treba použiť v nejakom ensembli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensebmle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšal som viacero Ensemble spôsobov (Voting, Bagging, RandomForest, Boosting) s rôznymi úspechmi a rýchlosťami predikcie. Nižšie však uvádzam iba 2 ktorých pomer rýchlosti a presnosti bol zo všetkých najlepší."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aj pri Ensembly budem mať 2 spôsoby - jeden s ukladaním a jeden bez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=50, max_depth=7, n_jobs=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('forest.pk1'):\n",
    "    forest = joblib.load('forest.pk1')\n",
    "else:\n",
    "    forest = RandomForestClassifier(n_estimators=50, max_depth=7, n_jobs=1).fit(X, y)\n",
    "    joblib.dump(forest, 'forest.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = forest.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('forest.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv forest.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidím, že úspešnosť nie je moc dobrá a dala by sa zlepšiť úpravou parametrou. Avšak už pri tomto nastavení parametrov to ledva zvláda pamäťovo Random Forest a keď ich iba o trochu upravím (zvýšim počet/hĺbku) tak padá na nedostatok pamäte. Preto som sa rozhodol spraviť aj Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skúšal som viac nastavení Bagging klasifikátoru a tento čo nasleduje sa ukázal, že dáva najlepšie výsledky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvý spôsob - jednorázové použitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging_forest = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=None,\n",
    "                                                                             random_state=42),\n",
    "                                       n_estimators=150, max_samples=0.5, max_features=0.5, random_state=42).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druhý spôsob - ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os.path as pth\n",
    "\n",
    "if pth.exists('bagging_forest.pk1'):\n",
    "    bagging_forest = joblib.load('bagging_forest.pk1')\n",
    "    print('bagging_forest')\n",
    "else:\n",
    "    bagging_forest = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=None,\n",
    "                                                                             random_state=42),\n",
    "                                       n_estimators=150, max_samples=0.5, max_features=0.5, random_state=42).fit(X, y)\n",
    "    joblib.dump(bagging_forest, 'bagging_forest.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keď mám model natrénovaný tak môžem predikovať validačné dáta a zistiť úspešnosť predikcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_valid = bagging_forest.predict(trans_valid)\n",
    "print(np.count_nonzero(out_valid == valid_test)/len(valid_test) * 100)\n",
    "out_valid.tofile('bagging_forest.csv', sep='\\n', format=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto porovnanie však ráta s predikovaním aj triedy 0 a preto použijem na kontrolu aj priamo dodaný skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run eval.py valid_target.csv bagging_forest.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidím, že takto nastavený Bagging má veľmi dobrú úspešnosť a rýchlosť predikcie a preto ho aj použijem pri predikcii testovacích dát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predikcia finálnych hodnôt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz si už môžem načítať testovacie dáta a vytvoriť finálny csv súbor s predikovanými triedami. Testovacie dáta si budem zase musieť najprv upraviť pred predikciou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\", sep='\\t')\n",
    "trans_test = pd.DataFrame()\n",
    "for word in list(test_data.columns.values):\n",
    "    if word not in name_list:\n",
    "        trans_test[word] = boxcox(test_data[word] + 1, lmbda=box_param[word][0])\n",
    "\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in list(trans_test.columns.values):\n",
    "    if word not in name_list:\n",
    "        trans_test[word] = normalization(trans_test[word], percentile[word][0], percentile[word][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_test = bagging_forest.predict(trans_test)\n",
    "out_test.tofile('test_out.csv', sep='\\n', format=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
